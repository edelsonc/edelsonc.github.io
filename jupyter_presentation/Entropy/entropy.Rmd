---
title: "Entropy for Data Science"
author: Charlie Edelson, Caleb Dowdy, Chris Leonard,  Nicole Navarro, Aaron Niskin, Lance Price
date: "12/4/2017"
output:
    beamer_presentation: 
        theme: "EastLansing"
        color: "seahorse"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Outline
* History
    - Statistical Mechanics
    - Information Theory
* Shannon Entropy
    - Uniform Distribution
    - Normal Distribution
* Tsallis Entropy

# History

## Statistical Mechanics
Consider a box with $N$ particles of a monatomic gas

\begin{figure}
        \centering
        \includegraphics[width=0.5\textwidth]{images/particles.png}
\end{figure}

How would you model this?

## Statistical Mechanics - State Variables?

* We can talk about state variables: $P$, $T$, $N$, and $V$ \pause 

    - Ideal Gas Law

\begin{equation}
    PV = nRT    
\end{equation} \pause

* Characterize System Behaviors

## Statistical Mechanics - Ensemble Statistics
\begin{columns}
    \begin{column}{0.4\textwidth}
       \begin{figure}
                \includegraphics[width=0.5\textwidth]{images/newton-particles.png}
        \end{figure}
    \end{column}
    \begin{column}{0.6\textwidth}
        Assume each particle obeys Newton's Law
        \begin{itemize}
            \item{ $v_{0}$ and $x_0$ determines system}
            \item{Impractical for large $N$}
        \end{itemize}
        \pause
        \vspace{0.2cm}
        James Maxwell's Kinetic Theory of Gases
        \begin{itemize}
            \item{Consider Ensamble Statistics}
        \end{itemize} \vspace{0.2cm}
        \begin{equation}
            PV = \frac{Nm\bar{v^2}}{3}
        \end{equation}
    \end{column}
\end{columns}

## Statistical Mechanics Entropy
\begin{center}
    Average Behaviour $\rightarrow$ Macroscopic Properties
\end{center}
\pause
Ludwig Boltzman's statistical mechanical entropy
\begin{equation}
    S = k_b\ln(\Omega)
\end{equation}

$\Omega$ is the multiplicity of a given macrostate

## Macrostates, Microstates, and Multiplicity
Consider non-interacting paramagnet with 3 dipoles
\begin{figure}
        \centering
        \includegraphics[width=0.5\textwidth]{images/spins.png}
\end{figure} \pause

\vspace{-.2cm}

* Macrostate -  2 Up, 1 Down \pause

* Microstate - $\uparrow$, $\downarrow$, $\uparrow$ \pause

* $\Omega = {{N}\choose{N_\uparrow}} = {{3}\choose{2}}$

## Entropy of 100 Dipole Paramagnet

```{r, echo=FALSE}
N <- 100
kb <- 1.38064852e-23
ups <- c(0:N)
multiplicity <- choose(N, ups)
entropy <- kb * log(multiplicity)
plot(ups, multiplicity, xlab = expression(N[symbol("\255")]), ylab = "Entropy")
```

## Interpretation
Features of paramagnet entropy

* Minimum at 0 and 100 $\rightarrow$ 1 microstate each
* Maximum at 50 $\rightarrow \space 10^{29}$ microstates! \pause

Measure of ``mixed-up-ness" of a physical system

* Higher entropy $\rightarrow$ more mixing (randomness)
* Lower entropy $rightarrow$ less mixing
